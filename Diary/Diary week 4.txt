Diary week 4

2018 12 Mar

Model is optimised, and F1_score recorded, to consider taking a few more scores to compare the cross-validation before after optimisation.

Final code due on Friday; the readme is supposed to have clear instructions as to how to run the scripts. Important to have finished all the tasks in stated in the website to earn a grade of 'C' or higher.

Remaining tasks:

Add evolutionary information by running psi-blast and extracting the information
Use simple decision tree and compare the performance with the SVM performance.
Extract the data from 50 other proteins (new sequences with topologies! from PDB?) and test the performance (validate predicted against true topology). Source of dataset->old publications.

To improve code by allowing input via the command line instead of hard coding it in the python script. Joblib is not the best way to store the model, it may be better to use pickle instead to save the model.

Calculate comparison for MattCorr between new and old models: MattCorr for optimised model is 0.4135, and 0.3689 for the non-optimised model.

Wrote a simple python script FASTAParser.py to parse the dataset into individual FASTA files per sequence, as preparation for input to PSI-BLAST. Wrote a bash script PSSMBash.sh to iterate through all FASTA text files in the previously parsed FASTA directory to run a PSI-BLAST (e-value=0.01, iterations=3) to output to an ASCII format .pssm file for each sequence, using the SWISSPROT database.

2018 13 Mar

Writing new script PSSMParser.py to parse individual PSSM files, while saving the header ID. This header ID is subsequently used to call the corresponding topology from the original dataset, with both header and ID saved to lists in corresponding order. This will allow the generation of a list of vectors per sequence with corresponding topologies.

The tricky part of this code will be running through all PSSM files in the folder and compiling each list of vectors and topologies to a single final array to be fed to SVM.

Using a logical approach to this problem, the dataset was first parsed to return a list of IDs and list of states, followed by which each PSSM file relevant to the IDs was retrieved from the folder and added to a massive list of sliding windows. The appropriate states was also encoded and placed in a list of its own. These 2 lists were then converted to numpy arrays and fed to SVM's SVC. Because of the prior optimisation using GridSearch, the appropriate set of parameters for the dataset have already been determined (windowsize=21, gamma=0.01, C=5, and kernel=rbf). A variety of metrics should now be measured for this model and compared against that of AA sequence model.

Performing a cross_val_score using the above parameters and a 3 fold test, returned a mean f1 score of 0.758 for testfilesize50. This is slightly higher than the optimised AAseq trained model which returned a mean f1 score of 0.737. The confusion matrix for the PSSM model is as follows:
[[4364 1666]
 [1941 5655]]

This indicates a total of 3607 false hits as compared to 4030 false hits in the optimised AAseq model, and 4285 for the unoptimised AAseq model.

Running the MCC test using the PSSM sequences with the same parameters gives a score of 0.464, compared to 0.413 for the AAseq model.

2018 14 Mar

Continuing to run analysis using different classifiers, running the simple decision tree classifier on the AAseq model with randomstate=10, cvfold=3, and windowsize=21 returns a mean score of 0.613, and an f1_score of 0.653.

Running the decision tree on the PSSM model with the same parameters above returns a score of 0.691. Running the randomforestclassifier using the same parameters and PSSM model returns an f1 score of 0.724, compared to 0.688 for the AAseq model.

Important to feed the PSSM model a PSSM input and not the amino acid sequence!

Testing the final trained model with new data, possible analysis of data includes accuracy, recall score, f1 score, Matthews correlation, and confusion matrix.

Results returned for the AA seq model are accuracy of 0.705 and f1 score of 0.702, and for the PSSM model accuracy of 0.735, and f1 score of 0.734.

Testing the final trained AAseq model with 50Extra.txt returns an MCC of 0.405, and for the PSSM model 0.468. 

Confusion matrix for fully trained AA seq model:

[[4289 1987]
 [2169 5652]]

Confusion matrix for fully trained PSSM model:

[[4616 1660]
 [2068 5753]]

To transfer all the relevant metrics to a spreadsheet for easy comparison and referral.

Implemented an output for FinalPredictor.py, to write the predicted states to a separate file, along with original ID and sequence information. 

2018 15 Mar

To compare the performance of a more comprehensive model vs the 50 model, a bigger subset of the original dataset was taken (317proteins.txt), which excludes the 50 proteins found in 50Extra.txt, to avoid training on test data. Will run a similar prediction to the AA seq model (out_50), and compare scores as well as performance time.
